{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Code First, Math Later\n",
    "## Learning Neural Nets Through Implementation and Examples\n",
    "### Kyle Shaffer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Talk Overview\n",
    "* Overview of Deep Learning and Applications\n",
    "* Introduction to Keras API\n",
    "* Implementing Neural Networks\n",
    "* Beyond the Black Box: Investigating Feature Extraction Layers\n",
    "* Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Overall Approach\n",
    "* Many people start with textbooks and lessons to learn theory and fundamentals before moving on to application\n",
    "* Mathematics and formal notation can be abstract and difficult to understand\n",
    "* We can instead combine fundamentals with examples\n",
    "* Recent deep learning libraries have made prototyping much easier, but these tools can also be used to learn about neural networks prior to application"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## We'd like to go from this....\n",
    "$$i = \\sigma(x_{t}U^i + s_{t-1}W^i)$$\n",
    "$$f = \\sigma(x_{t}U^f + s_{t-1}W^f)$$\n",
    "$$o = \\sigma(x_{t}U^o + s_{t-1}W^o)$$\n",
    "$$g = \\tanh(x_{t}U^g + s_{t-1}W^g)$$\n",
    "$$c_{t} = c_{t-1} \\cdot f + g \\cdot i$$\n",
    "$$s_{t} = \\tanh(c_{t}) \\cdot o$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## To this!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def build_lstm():\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(64))\n",
    "    model.add(Dense(1))\n",
    "    model.add(Activation('sigmoid'))\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Quick Intro to Deep Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Feedforward Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Feedforward Networks\n",
    "* __Deep learning__ = models that represent data hierarchically in order to make a prediction\n",
    "* Deeper layers in this hierarchy automatically identify more general / abstract features\n",
    "* Traditional ML feature engineering vs. DL architecture engineering\n",
    "* __Feedforward nets__ = prototypical example of deep networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "![title](figs/neural-network.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Feedforward Networks\n",
    "## Some vocab...\n",
    "* **_layers_**: arrangements of neurons/cells with no lateral connections\n",
    "* **_activation function_**: non-linear function that modifies values of a vector and passes these values to a subsequent layer\n",
    "* **_\"deep\" network_**: neural network with several layers stacked on top of one another\n",
    "* **_hidden layer_**: layer in a neural network that is neither the input or output layer (in the middle)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Feedforward Networks\n",
    "## Some vocab...\n",
    "* **_multilayer perceptron_**: another term for feedforward networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Feedforward Networks\n",
    "* Often think of hidden layers as \"feature extractors\" or \"data transformers\"\n",
    "* These layers have their weights adjusted through the training process, and they \"learn\" representations that are good for a predictive task\n",
    "* Different way of thinking from traditional process of manually engineering features before feeding to model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Feedforward Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "<tr>\n",
    "    <td> <img src=\"figs/neural-network.png\" alt=\"\" style=\"width: 700px;\"/> </td>\n",
    "    <td> <img src=\"figs/mlp_code.png\" alt=\"\" style=\"width: 700px;\"/> </td>\n",
    "</tr>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# Build a simple MLP NN\n",
    "mlp = Sequential()\n",
    "mlp.add(Dense(input_dim=4, units=5)) # Input (4) and hidden layers (5)\n",
    "mlp.add(Activation('relu')) # Activation function that links layers\n",
    "mlp.add(Dense(1)) # Final output layer\n",
    "mlp.add(Activation('sigmoid'))\n",
    "mlp.compile(loss='binary_crossentropy', optimizer='sgd')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Convolutional Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Convolutional Networks\n",
    "* Often used in image tasks\n",
    "* Idea of using a \"sliding filter\" to aggregate features over an image\n",
    "* Network passes learned feature representations to following layers\n",
    "* Each subsequent convolutional layer learns more general / abstract concepts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "![conv-layers](figs/conv_layers.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## What's a convolution?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "edge_filter = np.array([\n",
    "    [1, 0, -1], \n",
    "    [0, 0, 0],\n",
    "    [-1, 0, 1]\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# Convolution function\n",
    "# Here, we're detecting edges in an image\n",
    "\n",
    "def convolve(input_image, kernel):\n",
    "    padded_image = np.pad(input_image, (1, 1), 'constant')\n",
    "    kernel_width = kernel.shape[0]\n",
    "    kernel_height = kernel.shape[1]\n",
    "    \n",
    "    # We'll store the convolved image in this NumPy array\n",
    "    convolved_image = np.zeros_like(input_image)\n",
    "    \n",
    "    for i in xrange(padded_image.shape[0] - kernel_width + 1):\n",
    "        for j in xrange(padded_image.shape[1] - kernel_height + 1):\n",
    "            # Extract an image chunk of size kernel_width x kernel_height\n",
    "            temp_array = padded_image[i: i+kernel_width, j: j+kernel_height]\n",
    "            conv_val = np.sum(temp_array * kernel)\n",
    "            # Clip values outside the 0 - 255 range\n",
    "            if conv_val < 0:\n",
    "                push_val = 0\n",
    "            elif conv_val > 255:\n",
    "                push_val = 255\n",
    "            else:\n",
    "                push_val = conv_val\n",
    "            convolved_image[i, j] = push_val\n",
    "    return convolved_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# Let's read in an image and view it\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "% matplotlib inline\n",
    "\n",
    "img_height, img_width = 12, 8\n",
    "img = np.array(Image.open(\"figs/space_needle2.png\"))\n",
    "single_channel_img = img[:, :, 0]\n",
    "plt.figure(figsize=(img_height, img_width))\n",
    "plt.imshow(single_channel_img, plt.get_cmap('gray'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "img_edges = convolve(single_channel_img, edge_filter)\n",
    "plt.figure(figsize=(img_height, img_width))\n",
    "plt.imshow(img_edges, plt.get_cmap('gray'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## What's a convolution?\n",
    "![conv-img](figs/convolution.gif)\n",
    "Source: Source: http://deeplearning.stanford.edu/wiki/index.php/Feature_extraction_using_convolution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Recurrent Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Recurrent Networks\n",
    "* Capture sequential dependencies in data\n",
    "* Often used for language / text data or time series\n",
    "* Learn a \"cell state\" that represents relationships between items in input sequence\n",
    "* These come in several flavors (GRU, LSTM, Bidirectional RNN)\n",
    "* Caveats: can take very long time to train, optimization can be tricky"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "![lstm-unrolled](figs/lstm_unrolled.png)\n",
    "Source: http://colah.github.io/posts/2015-08-Understanding-LSTMs/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "![inside-lstm](figs/inside_lstm.png)\n",
    "Source: http://colah.github.io/posts/2015-08-Understanding-LSTMs/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Introduction to Keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Keras Homepage\n",
    "https://keras.io/\n",
    "![keras-homepage](figs/keras_homepage.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Introduction to Keras\n",
    "* Abstracts implementation details\n",
    "* Allows for quick prototyping\n",
    "* Think in terms of \"stacking layers\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# General pattern of writing Keras models\n",
    "\n",
    "# (1) Start a \"container\" of model layers\n",
    "# (2) Add initial input and feature extraction layers\n",
    "# (3) Finally add output layer for final predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# (1) Start a \"container\" of model layers\n",
    "model = Sequential()\n",
    "\n",
    "# (2) Add initial input and feature extraction layers\n",
    "model.add(Dense(100))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dense(100))\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "# (3) Finally add output layer for final predictions\n",
    "model.add(Dense(1))\n",
    "model.add(Activation('sigmoid'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Implementing Neural Nets: Examples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# CNN for Object Recognition\n",
    "* CIFAR 10 Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Keras Datasets\n",
    "https://keras.io/datasets/\n",
    "![Datsets](figs/keras_datasets.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 32, 32, 3)\n"
     ]
    }
   ],
   "source": [
    "from keras.datasets import cifar10\n",
    "\n",
    "(X_train, y_train), (X_test, y_test) = cifar10.load_data()\n",
    "\n",
    "print X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(32, (3, 3), padding='same',\n",
    "                 input_shape=x_train.shape[1:]))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv2D(32, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Conv2D(64, (3, 3), padding='same'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv2D(64, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(512))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(num_classes))\n",
    "model.add(Activation('softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# RNN / LSTM for Document Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Beyond the Black Box: Investigating Feature Extraction Layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### - Visualizing probability layers\n",
    "### - Visualizing and investigating feature extraction layers \n",
    "### - Visualizing an embedding layer from trained net (?)\n",
    "### - Looking at LSTM weight output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# Building our model architecture...\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Embedding, Flatten, LSTM\n",
    "\n",
    "def build_lstm_model():\n",
    "    model = Sequential()\n",
    "    # Embedding layer\n",
    "    model.add(Embedding(input_dim=2000, output_dim=200, input_length=100))\n",
    "    # Recurrent layers\n",
    "    model.add(LSTM(64))\n",
    "    model.add(LSTM(64)) # Let's make a deeper LSTM!\n",
    "    # Additional fully connected layers\n",
    "    model.add(Dense(128, activation='relu'))\n",
    "    model.add(Dropout(0.2))\n",
    "    # Layer that actually does the classification\n",
    "    model.add(Dense(4, activation='softmax'))\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='sgd')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# Cool, let's build our model so we can use it - oh wait...\n",
    "lstm_model = build_lstm_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "def build_lstm_feature_extractor():\n",
    "    model = Sequential()\n",
    "    # Embedding layer\n",
    "    model.add(Embedding(input_dim=2000, output_dim=200, input_length=100))\n",
    "    model.add(LSTM(64))\n",
    "    # In principle, this last step doesn't make much sense\n",
    "    # But, we need to compile a model in order to play with it\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='sgd')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "partial_model = build_lstm_feature_extractor()\n",
    "# Let's make some fake data\n",
    "X_fake = np.array([np.random.randint(low=0, high=1, size=100) \n",
    "                   for _ in xrange(100)])\n",
    "print \"Shape of our fake data:\", X_fake.shape\n",
    "\n",
    "lstm_features = partial_model.predict(X_fake)\n",
    "print \"Shape of feature data from first LSTM layer:\", lstm_features.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Retrieving Layer Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Keras models have a `layers` attribute that is simply\n",
    "# a list containing the (wait for it) layers of your model\n",
    "partial_model.layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Retrieving Recurrent Weights to Understand Network Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "# We can also return the actual weights from these layers\n",
    "lstm_weights = partial_model.layers[1].get_weights()\n",
    "print type(lstm_weights)\n",
    "print len(lstm_weights)\n",
    "\n",
    "for weight_matrix in lstm_weights:\n",
    "    print weight_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# Still just NumPy arrays!\n",
    "lstm_weights[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Recap\n",
    "* We've gone over popular architectures and some fundamentals in deep learning\n",
    "* Learned about Keras as a tool to implement and experiment with these architectures\n",
    "* Found ways to \"peer into\" network architectures to better understand data transformations as they happen in the network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Recap\n",
    "* Taken some of the \"mystery\" out of neural networks\n",
    "* Nothing magic - vectors, matrices, functions which can be implemented in familiar tools (NumPy)\n",
    "* Iterative approach to learning about neural networks - fundamentals/theory -> practice -> repeat!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Thanks! Questions?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
